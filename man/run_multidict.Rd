% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/run-multidict.R
\name{run_multidict}
\alias{run_multidict}
\title{Run a dictionary with patterns that might match more than one term (or token)}
\usage{
run_multidict(
  corpus,
  dict,
  at_level = c("sentences", "paragraphs", "documents"),
  return_value = c("count", "binary", "prop", "count_at_level", "prop_at_level"),
  include_totals = TRUE,
  return_result_only = FALSE,
  pattern_type = c("regex", "glob", "coll", "fixed"),
  case_insensitive = TRUE,
  regex_optimize = FALSE,
  regex_make_greedy = FALSE,
  regex_make_lazy = FALSE,
  dict_name,
  custom_replacement,
  tolower = case_insensitive,
  stem = FALSE,
  remove = NULL,
  ...
)
}
\arguments{
\item{corpus}{A quanteda corpus object or something that can be transformed
to a corpus by quanteda::corpus(), for example, a simple character vector}

\item{dict}{A character vector where each element is a pattern or a
quanteda dictionary object with one dictionary.}

\item{at_level}{At which level should patterns be applied. Possible values
are "documents", "sentences", or "paragraphs". Defaults to "sentences".}

\item{return_value}{How should the value be returned? Possible values
include "count", "binary", "prop", "count_at_level", or "prop_at_level". You
get the results from the dictionary at the document level. "count" (the
default) gives  the simple frequency of dictionary hits in each document.
"count_at_level" gives you the number of sentences or paragraphs in a
document where there was at least one pattern match. Together with the
include_totals parameter "count" and "count_at_level" give you the most
flexibility to work with the results. "binary" returns 0 or 1, depending on
whether there was at least one pattern match in the document. "prop" is the
proportion of pattern matches relative to the total number of tokens in the
document. "prop_at_level" gives you the proportion of sentences or
paragraphs (in a document) where a pattern match was found.}

\item{include_totals}{Should the number sentencens (as "n_sentences") and
number of tokens (as "n_tokens") per document also be returned? Defaults to
TRUE.}

\item{return_result_only}{If TRUE, a data.frame containing the results will
be returned. If FALSE (the default), you will get the provided corpus with
the results attached as new columns.}

\item{pattern_type}{The type of pattern included in the dictionary. Defaults
to "regex" for regular expressions. "glob" is also possible for glob style
wildcards. Internally, glob patterns are transformed to regex patterns.
Other, usually not needed, possible values include "coll" and "fixed". See
the stringr package for details on pattern types.}

\item{case_insensitive}{Should the case be ignored when searching for
pattern matches? Defaults to TRUE.}

\item{regex_optimize}{Should the regular expressions be optimized by adding
word boundaries and removing open wildcards at word boundaries? This is
intended for using regular expression dictionary patterns the way I use
them in the popdictR package. It then allows for quicker lookups (see
regexhelpeR::optimize_regex_patterns)? Defaults to FALSE, so your patterns
are not changed.}

\item{regex_make_greedy}{Should regular expressions be transformed to greedy
versions? Defaults to FALSE. Usually not needed. If you switch this to TRUE,
while at the same time setting regex_make_lazy to TRUE as well, you will get
inverted patterns (i.e., lazy patterns become greedy and greedy patterns
become lazy).}

\item{regex_make_lazy}{Should regular expressions be transformed to lazy
versions? Defaults to FALSE, so your patterns are not changed. However, you
should probably use lazy regex patterns to replace the shortest possible
compounds.}

\item{dict_name}{You can set a custom name for your dictionary. This is also
the name of the variable that contains the results in the return value. If
you provided a quanteda dictionary, the name of the first dictionary
included will be used. Otherwise, the dict_name defaults to "dict".}

\item{custom_replacement}{Internally, this function replaces pattern matches
with a random string (containing 40 random letters and 10 random numbers)
before running quanteda's dictionary lookup function on the corpus. The
random string should be unique and there is usually no need to set a custom
string.}

\item{tolower}{Forwarded to quanteda's dfm function, converts all features
to lowercase. Defaults to the value for "case_insensitive."}

\item{stem}{Forwarded to quanteda's dfm function. If TRUE, quanteda stems
words. Defaults to FALSE.}

\item{remove}{Forwarded to quanteda's dfm function. A list of stopwords
which are removed from the dfm before running the dictionary.}

\item{...}{Additional arguments passed on to quanteda's dfm function (and
there to the tokens function). Includes things such as "remove_punct",
"remove_symbols", "remove_numbers", etc. See quanteda's tokens function for
details.}
}
\value{
Returns the results of running the dictionary. If return_result_only
is set, you will get a data.frame with only the results. Otherwise, you the
results will be bound to the corpus as new columns. If you only provided
texts, the only other column will be these texts of course (variable x). If
you provided a quanteda corpus, the results will be stored as variables in
the docvars.
}
\description{
Quanteda's dictionary function does not allow for patterns with wildcards to
match more than one token. For example, a regular expression such as
"the (.*) people" would not work as expected if you wanted to match
expressions such as "the honest people" and "the good people". This
function facilitates the usage of dictionaries including such terms. It
could be considered the main function for the multidictR package.
Internally, the package uses stringr::str_replace_all to replace pattern
matches with a random string before then using quanteda to look this string
up in the corpus.
}
